# Refactor data loading to use manifest-based approach

## Problem

Current data loading in `bnl.data` uses runtime filesystem scanning which creates issues for:

- **Performance**: `os.walk` and `glob` operations on every dataset access
- **Portability**: Hardcoded local filesystem assumptions prevent hosted deployment
- **Brittleness**: Dataset-specific path resolution logic scattered across modules

## Solution

Replace filesystem scanning with **manifest files** (`metadata.csv`) that serve as authoritative data asset indexes.

### Manifest Format (Tidy CSV)
```csv
track_id,asset_type,asset_subtype,file_path
123,audio,mix,/path/to/123/audio.wav
123,annotation,reference,/path/to/123.jams
123,annotation,estimate_A,/path/to/estimates/123_method_A.jams
124,audio,mix,/path/to/124/audio.mp3
```

### Implementation Plan

1. **Create manifest generation script** (`scripts/build_manifest.py`)
2. **Refactor `BaseDataset` to use DataFrame lookups** instead of filesystem scanning
3. **Update dataset modules** (starting with `salami.py`)
4. **Remove filesystem scanning code**

### Benefits

- **Fast**: DataFrame lookups vs filesystem operations
- **Portable**: Manifests can reference URLs, cloud storage, etc.
- **Clean**: Single source of truth for data asset relationships
- **Scalable**: Easy to add new asset types without schema changes

## Acceptance Criteria

- [ ] Manifest generation script working for SALAMI
- [ ] `BaseDataset` refactored to use manifest lookups
- [ ] Existing API maintained (load_track, list_tids work as before)
- [ ] Performance improvement demonstrated
- [ ] Tests updated

---
**Priority**: High - blocking hosted deployment
**Effort**: Medium - clean refactor of existing logic 