{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ca4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_res = pd.read_feather('./monocasting_results.feather').replace(\n",
    "    {\n",
    "        'mono_casting': {'depth': 'Depth', 'prob': 'Weighted'},\n",
    "        'bdry_cleaning': {'absorb': 'Absorb', 'none': 'Default', 'kde': 'KDE'},\n",
    "        'leveling': {'unique': 'Default', 'mean_shift': 'Mean Shift'},\n",
    "    }\n",
    ").rename(\n",
    "    columns={'tid': 'track_id', 'mono_casting': 'P(t|H)', 'bdry_cleaning': 'B Clean-up', 'leveling': 'Level'}\n",
    ")\n",
    "\n",
    "b_res = pd.read_feather('./monocasting_bmeasure.feather').replace(\n",
    "    {\n",
    "        'mono_casting': {'depth': 'Depth', 'prob': 'Weighted'},\n",
    "        'bdry_cleaning': {'absorb': 'Absorb', 'none': 'Default', 'kde': 'KDE'},\n",
    "        'leveling': {'unique': 'Default', 'mean_shift': 'Mean Shift'},\n",
    "        'prf': {'f': \"F-score\", 'p': \"Prec\", 'r': \"Recall\"},\n",
    "    }\n",
    ").rename(\n",
    "    columns={\n",
    "        'mono_casting': 'P(t|H)', 'bdry_cleaning': 'B Clean-up', 'leveling': 'Level', \n",
    "        'b': 'B', 'hr': 'HR', 'poa': 'POA', 'poa-m': 'POA-m', 'b-m': 'B-m'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02c6d0",
   "metadata": {},
   "source": [
    "## Boundary clean-up effects story:\n",
    "cleaning up boundaries betters precision. With KDE a little bit better than absorb in terms of precision.\n",
    "F-measure wise tho, everyone is neck and neck, and no boundary cleaning does a little bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hr_prf(b_res, window='0.5', level='Default', pt='Depth', ax=None):\n",
    "    filtered_b_res = b_res.where(\n",
    "        (b_res['window']==window) & (b_res['Level']==level) & (b_res['P(t|H)']==pt)\n",
    "    ).dropna().reset_index(drop=True)\n",
    "\n",
    "    full_combo_b = filtered_b_res.pivot_table(\n",
    "        index=['track_id'], \n",
    "        columns=['B Clean-up', 'prf'], \n",
    "        values='HR'\n",
    "    )\n",
    "\n",
    "    new_columns = [\n",
    "        ': '.join([f for f in col if f not in ('')]) \n",
    "        for col in full_combo_b.columns.values\n",
    "    ]\n",
    "    full_combo_b.columns = new_columns\n",
    "    col_order = [\n",
    "        'Default: F-score', 'Default: Prec', 'Default: Recall', \n",
    "        'Absorb: F-score', 'Absorb: Prec', 'Absorb: Recall', \n",
    "        'KDE: F-score', 'KDE: Prec', 'KDE: Recall',\n",
    "    ]\n",
    "    full_combo_b = full_combo_b[col_order]\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # color cycler for F-score, Prec, and Recall\n",
    "    colors =  ['#4477AA', '#EE6677', '#228833']  # blue, red, green\n",
    "    palette = [colors[i // 3] for i in range(len(col_order))]\n",
    "    ax = sns.violinplot(data=full_combo_b, ax=ax, palette=palette)\n",
    "\n",
    "    # Calculate means and put text in a box on each violin plot\n",
    "    means = full_combo_b.mean()\n",
    "    for i, mean in enumerate(means):\n",
    "        # Get the maximum value for this column to position text above it\n",
    "        text_y = [0.75, 0.85, 0.95] * 3\n",
    "        ax.text(\n",
    "            i, text_y[i], f'μ={mean:.3f}', \n",
    "            ha='center', va='bottom', fontsize=9,\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    ax.set(\n",
    "        title=f'Hit-Rate ({window} sec) for different Boundary Clean-up Strategy',\n",
    "        ylabel=f'Hit Rate ({window} sec)',\n",
    "        xlabel='Boundary Clean-up Strategy'\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(6, 10), sharex=True)\n",
    "for i, window in enumerate(['0.5', '1.5', '3.0']):\n",
    "    plot_hr_prf(\n",
    "        b_res, window=window, level='Default', pt='Depth', ax=axs[i]\n",
    "    )\n",
    "fig.savefig(\"cleanup_effects_on_bhr.pdf\", bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de9aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d983d8fc",
   "metadata": {},
   "source": [
    "## Let's look at POA metrics and B-measure\n",
    "\n",
    "Weighted + Mean Shift wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bmeasure_violin(b_result, window='0.5', prf='F-score', metric='POA', figsize=(7.5, 7), ax=None):\n",
    "    filtered_result = b_result.where(\n",
    "        (b_result['window']==window) & (b_result['prf']==prf)\n",
    "    ).dropna().reset_index(drop=True)\n",
    "\n",
    "    full_combo_b = filtered_result.pivot_table(\n",
    "        index=['track_id'], \n",
    "        columns=['P(t|H)', 'B Clean-up', 'Level'], \n",
    "        values=metric\n",
    "    )\n",
    "\n",
    "    new_columns = ['+'.join([f for f in col if f not in ('', 'Default')]) for col in full_combo_b.columns.values]\n",
    "    full_combo_b.columns = new_columns\n",
    "    col_order = [\n",
    "        'Depth', 'Depth+Absorb', 'Depth+KDE', \n",
    "        'Depth+Mean Shift', 'Depth+Absorb+Mean Shift', 'Depth+KDE+Mean Shift', \n",
    "        'Weighted', 'Weighted+Absorb', 'Weighted+KDE', \n",
    "        'Weighted+Mean Shift', 'Weighted+Absorb+Mean Shift', 'Weighted+KDE+Mean Shift', \n",
    "    ]\n",
    "    full_combo_b = full_combo_b[col_order]\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.violinplot(data=full_combo_b, ax=ax)\n",
    "    \n",
    "    # Calculate means\n",
    "    means = full_combo_b.mean()\n",
    "    # Create new labels with the mean on a new line\n",
    "    # new_labels = [f\"{label}\\nμ={mean:.3f}\" for label, mean in zip(col_order, means)]\n",
    "    # ax.set_xticks(ax.get_xticks()) # Prevents a UserWarning\n",
    "    # ax.set_xticklabels(new_labels, rotation=45, ha='right')\n",
    "    for i, mean in enumerate(means):\n",
    "        # Get the maximum value for this column to position text above it\n",
    "        text_y = [0.72, 0.82, 0.92] * 4\n",
    "        ax.text(\n",
    "            i, text_y[i], f'μ={mean:.3f}', \n",
    "            ha='center', va='bottom', fontsize=9,\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "\n",
    "    ax.set(\n",
    "        ylim=(0, 1),\n",
    "        title=f'{metric} {prf} ({window} sec) for Different Strategy Combinations',\n",
    "        ylabel=f'{metric} {prf} ({window} sec)',\n",
    "        xlabel='Strategy Combo'\n",
    "    )\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    # plt.close(fig)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(6, 10), sharex=True, sharey=True)\n",
    "for i, window in enumerate(['0.5', '1.5', '3.0']):\n",
    "    plot_bmeasure_violin(b_res, window=window, prf=\"F-score\", metric=\"POA\", ax=axs[i])\n",
    "fig.savefig(\"combo_effect_on_poa.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(6, 10), sharex=True, sharey=True)\n",
    "for i, window in enumerate(['0.5', '1.5', '3.0']):\n",
    "    plot_bmeasure_violin(b_res, window=window, prf=\"F-score\", metric=\"B\", ax=axs[i])\n",
    "fig.savefig(\"combo_effects_on_bmeasure.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(6, 10), sharex=True, sharey=True)\n",
    "for i, window in enumerate(['0.5', '1.5', '3.0']):\n",
    "    plot_bmeasure_violin(b_res, window=window, prf=\"Prec\", metric=\"B\", ax=axs[i])\n",
    "# fig.savefig(\"combo_effects_on_bmeasure.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(6, 10), sharex=True, sharey=True)\n",
    "for i, window in enumerate(['0.5', '1.5', '3.0']):\n",
    "    plot_bmeasure_violin(b_res, window=window, prf=\"Recall\", metric=\"B\", ax=axs[i])\n",
    "# fig.savefig(\"combo_effects_on_bmeasure.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0253dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f036c229",
   "metadata": {},
   "source": [
    "## Scatter plots to show effects of mono casting on B-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f990035",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_result = b_res.where(\n",
    "    (b_res['window']=='0.5') & (b_res['prf']=='F-score')\n",
    ").dropna().reset_index(drop=True)\n",
    "\n",
    "full_combo_b = filtered_result.pivot_table(\n",
    "    index=['track_id', 'B Clean-up', 'Level'], \n",
    "    columns=['P(t|H)'], \n",
    "    values='B'\n",
    ")\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=full_combo_b, x=\"Depth\", y=\"Weighted\", \n",
    "    col=\"Level\", row=\"B Clean-up\", \n",
    "    alpha=0.3, s=15,\n",
    "    height=3.2, aspect=1,\n",
    "    rasterized=True\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.plot([0,1],[0,1], \"r--\")\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.suptitle(\"Choice of P(t|H)'s Effect on B-measure (0.5 sec)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prom_func_effects_b05.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_result = b_res.where(\n",
    "    (b_res['window']=='0.5') & (b_res['prf']=='F-score')\n",
    ").dropna().reset_index(drop=True)\n",
    "\n",
    "full_combo_b = filtered_result.pivot_table(\n",
    "    index=['track_id', 'P(t|H)', 'B Clean-up'], \n",
    "    columns=['Level'], \n",
    "    values='POA'\n",
    ")\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=full_combo_b, x=\"Default\", y=\"Mean Shift\", \n",
    "    col=\"P(t|H)\", row=\"B Clean-up\", \n",
    "    alpha=0.3, s=15,\n",
    "    height=3.2, aspect=1,\n",
    "    rasterized=True\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.plot([0,1],[0,1], \"r--\")\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.suptitle(\"Level Quantization's Effect on POA (0.5 sec)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"level_quant_poa05.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1302e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boundary cleaning has very little effects\n",
    "\n",
    "reduced_bclean = b_res.pivot_table(\n",
    "    index=['track_id', 'P(t|H)', 'Level'], \n",
    "    columns=['B Clean-up'], \n",
    "    values='B'\n",
    ").reset_index()\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=reduced_bclean, x=\"Default\", y=\"KDE\", \n",
    "    col=\"P(t|H)\", row=\"Level\", \n",
    "    alpha=0.3, s=15,\n",
    "    height=3.2, aspect=1,\n",
    "    rasterized=True\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    ax.plot([0,1],[0,1], \"r--\")\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.suptitle(\"KDE Clean-up Effect on B-measure (0.5 sec)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"kde_vs_default_b05.pdf\")\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=reduced_bclean, x=\"Absorb\", y=\"KDE\", \n",
    "    col=\"P(t|H)\", row=\"Level\", \n",
    "    alpha=0.3, s=15,\n",
    "    height=3.2, aspect=1,\n",
    "    rasterized=True\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    ax.plot([0,1],[0,1], \"r--\")\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.suptitle(\"Absorption vs. KDE Effect on B-measure (0.5 sec)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"kde_vs_absorb_b05.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8951bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d06a7d8",
   "metadata": {},
   "source": [
    "## Comparing T-measure and B-measure on the same tracks's estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9147050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-measure and B-measure on \"Depth\" only\n",
    "\n",
    "t_by_depth = t_res.where(\n",
    "    (t_res['P(t|H)']=='Depth') \n",
    "    & (t_res.Level=='Default')\n",
    "    & (t_res['B Clean-up']=='Default')\n",
    ").dropna().pivot_table(\n",
    "    index='track_id', values=['t_reduced_f', 't_full_f']\n",
    ")\n",
    "\n",
    "t_by_combo = t_res.where(\n",
    "    (t_res['P(t|H)']=='Weighted') \n",
    "    & (t_res.Level=='Mean Shift')\n",
    "    & (t_res['B Clean-up']=='KDE')\n",
    ").dropna().pivot_table(\n",
    "    index='track_id', values=['t_reduced_f', 't_full_f']\n",
    ")\n",
    "\n",
    "b_by_depth = b_res.where(\n",
    "    (b_res['P(t|H)']=='Depth') \n",
    "    & (b_res.Level=='Default')\n",
    "    & (b_res['B Clean-up']=='Default')\n",
    "    & (b_res.prf=='F-score')\n",
    ").dropna().pivot_table(\n",
    "    index='track_id', columns='window', values=['B','POA','HR']\n",
    ")\n",
    "\n",
    "b_by_combo = b_res.where(\n",
    "    (b_res['P(t|H)']=='Weighted') \n",
    "    & (b_res.Level=='Mean Shift')\n",
    "    & (b_res['B Clean-up']=='KDE')\n",
    "    & (b_res.prf=='F-score')\n",
    ").dropna().pivot_table(\n",
    "    index='track_id', columns='window', values=['B','POA','HR']\n",
    ")\n",
    "\n",
    "combined_by_depth = pd.concat([t_by_depth, b_by_depth], axis=1, join='outer')\n",
    "combined_by_combo = pd.concat([t_by_combo, b_by_combo], axis=1, join='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_b_vs_t(combined_df, figsize=(5.5, 8)):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=figsize, sharex=True, sharey=True)\n",
    "    rows = [('B', w) for w in ['0.5', '1.5', '3.0']]\n",
    "    cols = ['t_reduced_f', 't_full_f']\n",
    "    col_label_map = {'t_reduced_f': 'T-measure (reduced)', 't_full_f': 'T-measure (full)'}\n",
    "\n",
    "    for b_option, ax_row in zip(rows, axs):\n",
    "        for t_option, ax in zip(cols, ax_row):\n",
    "            sns.scatterplot(\n",
    "                combined_df, x=t_option, y=b_option, \n",
    "                ax=ax, \n",
    "                s=12, alpha=0.5, rasterized=True\n",
    "            )\n",
    "            ax.plot([0,1], [0,1], 'r--')\n",
    "            ax.grid(True)\n",
    "            ax.set(\n",
    "                aspect='equal', \n",
    "                ylabel=f'B-measure ({b_option[1]} sec)',\n",
    "                xlabel=col_label_map[t_option]\n",
    "            )\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_b_vs_t(combined_by_depth)\n",
    "fig.suptitle(\"T-measure VS B-measure with\\nBaseline Monotonic Casting\")\n",
    "fig.tight_layout()\n",
    "fig.savefig('b_vs_t_baseline_monocasting.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_b_vs_t(combined_by_combo)\n",
    "fig.suptitle(\"T-measure VS B-measure with Best Monotonic Casting Combo\\nWeighted Prominence + KDE Cleaning + Mean Shift Leveling\")\n",
    "fig.tight_layout()\n",
    "fig.savefig('b_vs_t_best_monocasting.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f05aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b777f46b",
   "metadata": {},
   "source": [
    "## Comparing T-measure and B-measure on SALAMI reference annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cf4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-measure and B-measure on \"Depth\" only\n",
    "t_ref_res = pd.read_feather(\"mir_eval_slm_inter_anno_results.feather\")\n",
    "b_ref_res = pd.read_feather(\"bmeasure_slm_inter_anno_results.feather\")\n",
    "\n",
    "filtered_b_ref_res = b_ref_res.pivot_table(\n",
    "    index='track_id', columns=['prf', 'metric', 'window'], values='score'\n",
    ")['f']['b']\n",
    "\n",
    "\n",
    "combined_df = pd.concat([t_ref_res, filtered_b_ref_res], axis=1)\n",
    "combined_df.rename(columns={'T-Measure reduced': 'T-measure (reduced)', 'T-Measure full': 'T-measure (full)', 0.5: 'B-measure (0.5 sec)', 1.5: 'B-measure (1.5 sec)', 3: 'B-measure (3.0 sec)'}, inplace=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae264a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_b_vs_t_slm_ref(combined_df, figsize=(5.5, 8)):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=figsize, sharex=True, sharey=True)\n",
    "    rows = [f\"B-measure ({w} sec)\" for w in ['0.5', '1.5', '3.0']]\n",
    "    cols = ['T-measure (reduced)', 'T-measure (full)']\n",
    "\n",
    "    for b_option, ax_row in zip(rows, axs):\n",
    "        for t_option, ax in zip(cols, ax_row):\n",
    "            sns.scatterplot(\n",
    "                combined_df, x=t_option, y=b_option, \n",
    "                ax=ax, \n",
    "                s=12, alpha=0.5, rasterized=True\n",
    "            )\n",
    "            ax.plot([0,1], [0,1], 'r--')\n",
    "            ax.grid(True)\n",
    "            ax.set(aspect='equal')\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_b_vs_t_slm_ref(combined_df)\n",
    "fig.suptitle(\"T-measure vs B-measure\\nbetween 2 reference annotations on SALAMI tracks\")\n",
    "fig.tight_layout()\n",
    "fig.savefig('b_vs_t_slm_ref.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304e670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
